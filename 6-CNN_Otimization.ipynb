{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ocXmeXqbvy1n",
    "outputId": "3ca3bc77-c71e-4fc8-f736-f2d2f1935657"
   },
   "outputs": [],
   "source": [
    "import os, shutil, sys, random, cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import History\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pixW9vckvy1q"
   },
   "outputs": [],
   "source": [
    "dataset_dividido_folder = 'brain_tumor_dataset_dividido/'\n",
    "\n",
    "treino_folder = 'treino/'\n",
    "teste_folder = 'teste/'\n",
    "#validacao_folder = 'validacao/'\n",
    "\n",
    "dataset_dividido_folder_treino = dataset_dividido_folder + treino_folder\n",
    "dataset_dividido_folder_teste = dataset_dividido_folder + teste_folder\n",
    "#dataset_dividido_folder_validacao = dataset_dividido_folder + validacao_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SbciT_bdvy18"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYCvulY4vy18"
   },
   "outputs": [],
   "source": [
    "datagen_treino = ImageDataGenerator(rescale = 1./255,\n",
    "                                    brightness_range=(0.7, 1.3),\n",
    "                                    vertical_flip=True,\n",
    "                                    horizontal_flip=True,\n",
    "                                    validation_split = 0.25)\n",
    "\n",
    "#datagen_validacao = ImageDataGenerator(rescale = 1./255)\n",
    "datagen_teste = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "PdhfZrjUvy1_",
    "outputId": "3456558e-f29a-42ff-f829-e330d07f6286"
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "\n",
    "dados_treino = datagen_treino.flow_from_directory(\n",
    "    dataset_dividido_folder_treino,\n",
    "    target_size = (150,150),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = 32,\n",
    "    class_mode=\"binary\",\n",
    "    subset='training',\n",
    "    seed = seed)\n",
    "\n",
    "\n",
    "\n",
    "dados_validacao = datagen_treino.flow_from_directory(\n",
    "    dataset_dividido_folder_treino,\n",
    "    target_size = (150,150),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = 32,\n",
    "    class_mode=\"binary\",\n",
    "    subset='validation',\n",
    "    seed = seed)\n",
    "\n",
    "'''dados_validacao = datagen_validacao.flow_from_directory(\n",
    "    dataset_dividido_folder_validacao,\n",
    "    target_size = (150,150),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = 30,\n",
    "    class_mode=\"binary\",\n",
    "    seed = seed)'''\n",
    "\n",
    "dados_teste = datagen_teste.flow_from_directory(\n",
    "    dataset_dividido_folder_teste,\n",
    "    target_size = (150,150),\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = 32,\n",
    "    class_mode = 'binary'\n",
    "    )\n",
    "\n",
    "print(dados_treino.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dP9lj1SAvy2C"
   },
   "source": [
    "# Visualizar exemplo Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-U99DPE7vy2D",
    "outputId": "9f24d656-7ebc-404f-a27a-7d1b8802e9fa"
   },
   "outputs": [],
   "source": [
    "#.__getitem__(batch, max de 8)[atributos/class :0 -> atributos, 1 -> class][imagens, max de 29, batch_size 30]\n",
    "img = dados_treino.__getitem__(0)[0][1]\n",
    "x = image.img_to_array(img)\n",
    "plt.figure(0)\n",
    "plt.imshow(np.squeeze(x, axis=2), cmap = \"Greys\")\n",
    "plt.title('Imagem Inicial')\n",
    "x = x.reshape((1,) + x.shape)\n",
    "i = 1\n",
    "#.flow -> real time data augmentation.\n",
    "for batch in datagen_treino.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    plt.title('Imagem Gerada ' + str(i))\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]), cmap = \"Greys\", interpolation = \"nearest\")\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A7yUf2p570md"
   },
   "source": [
    "# Criar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Foi acrescentado ReduceLROnPlateau callback ao modelo.\n",
    "#Aplicando ReduceLROnPlateau  reduz a taxa de aprendizagem por um fator de 2-10 quando o processo de aprendizagem estagna.\n",
    "#O callback monitoriza o processo e se não houver melhorias em 'patience' epochs seguidas, a taxa de aprendizagem é reduzida.\n",
    "Reduce_learning_rate = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patiente = 2, cooldown = 2, min_lr = 0.00001, verbose = 1)\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", monitor = 'val_accuracy', verbose=1, save_best_only=True)\n",
    "callbacks = [checkpointer,Reduce_learning_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model_dynamic(num_neurons, input_size, output_size, dropout_size, activation, activation_output):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(num_neurons[0],(3,3), input_shape = (150,150,1), activation = activation))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    for i in range(1, len(num_neurons)):\n",
    "        model.add(Conv2D(num_neurons[i],(3,3), activation = activation))\n",
    "        model.add(MaxPolling2D(pool_size = (2,2)))\n",
    "        if dropout_size > 0: model.add(Dropout(dropout_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout_size))\n",
    "    model.add(Dense(64, activation = activation))\n",
    "    model.add(Dense(1, activation= activation_output))\n",
    "    \n",
    "    return model\n",
    "\n",
    "#model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_compile_model(model, optimizer, dados_treino, dados_validacao, lr, loss, epochs, steps_per_epochs, metric):\n",
    "    if optimizer == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = tf.keras.optimizers.Rmsprop(learning_rate = lr)\n",
    "    elif optimizer == 'sgd_momentum':\n",
    "        opt = tf.keras.optimizers.SGD(learning_rate = lr, momentum = 0.9)\n",
    "    else: opt = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "    model.compile(loss = loss, optimizer = opt, metrics = [\"accuracy\"])  #['\"' + metric + '\"'])\n",
    "    history = model.fit(dados_treino, steps_per_epoch = steps_per_epochs, epochs = epochs, validation_data = dados_validacao, callbacks = callbacks, verbose = 1)\n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dnn(dados_treino, dados_validacao, dados_teste, num_iterations, verbose = True):\n",
    "    best_accuracy = 0\n",
    "    num_neuron = [[64], [32]]\n",
    "    input_size = (150,150,1)\n",
    "    output_size = 1\n",
    "    dropouts = [0, 0.2, 0.4, 0.5]\n",
    "    metric = ['accuracy']\n",
    "    activations = ['relu', 'tanh']\n",
    "    activations_output = ['sigmoid']\n",
    "    losses = ['binary_crossentropy']\n",
    "    optimizers = [ 'adam', 'rmsprop', 'sgd_momentum']\n",
    "    epoch = [30, 15, 20]\n",
    "    steps_per_epochs = [5]\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        num_neurons = choice(num_neuron)\n",
    "        dropout = choice(dropouts)\n",
    "        metrics = choice(metric)\n",
    "        optimizer = choice(optimizers)\n",
    "        activation = choice(activations)\n",
    "        activation_output = choice(activations_output)\n",
    "        loss = choice(losses)\n",
    "        epochs = choice(epoch)\n",
    "        steps_per_epoch = choice(steps_per_epochs)\n",
    "        learning_rate = choice(learning_rates)\n",
    "        model = setup_model_dynamic(num_neurons, input_size, output_size, dropout, activation, activation_output)\n",
    "        model, history = setup_compile_model(model, optimizer,dados_treino, dados_validacao, learning_rate, loss, epochs, steps_per_epoch, metrics)\n",
    "        val_loss, val_accuracy = model.evaluate(dados_teste, verbose = 0)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"num_neurons\\tDropout\\tactivation\\tactivation_output\\tval_loss\\tval_accuracy\\n\")\n",
    "            print(num_neurons, \"\\t\", dropout, \"\\t\", \"\\t\", activation, \"\\t\", activation_output,\"\\t\", val_loss, \"\\t\", val_accuracy)\n",
    "        \n",
    "        if val_accuracy > best_accuracy:\n",
    "            best_accuracy = val_accuracy\n",
    "            best_configurations = (num_neurons, dropout, activation, activation_output, optimizer, loss, epochs, steps_per_epoch, learning_rate, metrics)\n",
    "    print(\"Best Accuracy: \", best_accuracy) \n",
    "    print(\"Configurations of model: Nª neurons: \" + str(best_configurations[0]) + \" dropout: \"+ str(best_configurations[1]) + \" activation: \"+ str(best_configurations[2]) + \" activation_output: \"+ str(best_configurations[3]) + \" activation_output: \"+ str(best_configurations[4]) + \" loss: \"+ str(best_configurations[5]) + \" epochs: \" + str(best_configurations[6]) + \" steps_per_epoch: \" + str(best_configurations[7])+ \" learning rate: \" + str(best_configurations[8]) + \" metric: \" + str(best_configurations[9]))\n",
    "    return best_configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_configurations = run_dnn(dados_treino, dados_validacao, dados_teste, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = setup_model_dynamic(best_configurations[0], 1, 1, best_configurations[1], best_configurations[2], best_configurations[3])\n",
    "best_model, history = setup_compile_model(best_model, best_configurations[0], dados_treino, dados_validacao, best_configurations[8], best_configurations[5], best_configurations[6], best_configurations[7], best_configurations[9])\n",
    "scores = best_model.evaluate(dados_teste, verbose = 0)\n",
    "print(\"Accuracy: \", scores[1] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "bUlQql6Gvy2Q",
    "outputId": "24a48ff8-268f-429f-a235-c6cf542f9e6a"
   },
   "outputs": [],
   "source": [
    "#Visualizar gráficos\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "#Gráfico Accuracy\n",
    "plt.plot(epochs, accuracy, 'b', color = 'green', label = 'Accuracy Treino')\n",
    "plt.plot(epochs, val_accuracy, 'b', label = 'Accuracy Validação')\n",
    "plt.title('Accuracy do treino e da validação')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "#Gráfico Loss\n",
    "plt.plot(epochs, loss, 'b', color = 'green', label = 'Loss Treino')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Loss Validação')\n",
    "plt.title('Loss do treino e da validação')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OWAQ-XLzvy2U",
    "outputId": "c9bb8bd3-c21a-451b-af61-f4ae3828a0e4"
   },
   "outputs": [],
   "source": [
    "def visualize_previsao(img, img_class):\n",
    "    print(\"X:\",img.shape)\n",
    "    print(\"y:\",img_class.shape)\n",
    "    plt.imshow(np.squeeze(img, axis=2))\n",
    "    plt.show()\n",
    "    print(\"label:\",img_class)\n",
    "    print(\"antes do aumento de mais uma dimensão:\",img.shape)\n",
    "    imagem_tensor = np.expand_dims(img, axis=0)\n",
    "    print(\"depois do aumento de mais uma dimensão:\",imagem_tensor.shape)\n",
    "    print(\"previsão:\",best_model.predict(imagem_tensor))\n",
    "    classes = best_model.predict_classes(imagem_tensor)\n",
    "    print('Classe prevista:',classes)\n",
    "    return imagem_tensor\n",
    "#dados_teste.__getitem__(0)[0], o primeiro 0 é a bacth dos dados, neste caso como dados_teste tem 52 imagens, uma bacth size de 10 vamos ter 6 batchs, podendo este número ir até 5\n",
    "# O segundo 0 é se queremos os atributos ou as labels (1)\n",
    "#dados_teste.__getitem__(0)[0][1] vamos buscar na bacth 0 os atributos da imagem 1 \n",
    "\n",
    "imagem_tensor = visualize_previsao(dados_teste.__getitem__(0)[0][1], dados_teste.__getitem__(0)[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlALD8eqvy2W",
    "outputId": "aa81e7d6-a43a-4b31-bb7c-e560169a81a4"
   },
   "outputs": [],
   "source": [
    "camadas_outputs = []\n",
    "for layer in best_model.layers[:4]:\n",
    "    print(layer.output.shape)\n",
    "    camadas_outputs.append(layer.output)\n",
    "\n",
    "# e depois criamos um modelo que retorna estes outputs dado os inputs do modelo\n",
    "activation_model = Model(inputs=best_model.input, outputs=camadas_outputs) \n",
    "activations = activation_model.predict(imagem_tensor)\n",
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)\n",
    "plt.imshow(first_layer_activation[0, :, :, 9], cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qMlw_BEvy2Z",
    "outputId": "2bafe58a-836c-45fc-bba3-c59ebeeb46cd"
   },
   "outputs": [],
   "source": [
    "nome_camadas = []\n",
    "for camada in best_model.layers[:4]:\n",
    "    print(\"Nome da camada: \", camada.name)\n",
    "    nome_camadas.append(camada.name)\n",
    "\n",
    "imagens_por_linha = 8 \n",
    "\n",
    "for nome_camada, ativacao_camada in zip(nome_camadas, activations): # o zip permite iterar simultaneamente em 2 listas\n",
    "    n_features = ativacao_camada.shape[-1] # Numero de features no feature map, pois é o que está na ultima dimensão\n",
    "    size = ativacao_camada.shape[1] #O feature map tem shape (1, tamanho, tamanho, numero_features).\n",
    "    n_linhas = -(-n_features // imagens_por_linha) # Empilha os canais de ativação nesta matriz\n",
    "    print(\"nome_camada:\",nome_camada)\n",
    "    print(\"n_features:\",n_features)\n",
    "    print(\"size:\",size)\n",
    "    print(\"n_linhas:\",n_linhas)\n",
    "    display_grid = np.zeros((size * n_linhas, imagens_por_linha * size))\n",
    "    for col in range(n_linhas): # para fazer o display com 15 imagens por linha\n",
    "        for lin in range(imagens_por_linha):\n",
    "            #verificar aqui se a imagem existe\n",
    "            imagem = ativacao_camada[0,:,:,col * imagens_por_linha + lin] #isto pode dar erro de out-of-range\n",
    "            imagem -= imagem.mean() # pos-processamento para melhor visualização\n",
    "            imagem /= imagem.std()\n",
    "            imagem *= 64\n",
    "            imagem += 128\n",
    "            imagem = np.clip(imagem, 0, 255).astype('uint8') #valores <0 ficam 0 e >255 ficam = 255\n",
    "            display_grid[col * size : (col + 1) * size,lin * size : (lin + 1) * size] = imagem\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
    "                        scale * display_grid.shape[0]))\n",
    "    plt.title(nome_camada)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TP_PG41067_PG41070 _V3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
